{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://github.com/walsvid/CoordConv/blob/master/coordconv.py\n",
    "https://medium.com/analytics-vidhya/encoding-time-series-as-images-b043becbdbf3\n",
    "https://eng.uber.com/coordconv/\n",
    "https://towardsdatascience.com/reading-charts-with-convolutional-neural-networks-cbaabdd5f478"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prerequisites\n",
    "\n",
    "Run the cells below if the named packages are not installed on your evironment yet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: alembic in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from optuna) (6.6.0)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: cliff in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from optuna) (3.10.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from optuna) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yvesd\\appdata\\roaming\\python\\python37\\site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: scipy!=1.4.0 in c:\\users\\yvesd\\appdata\\roaming\\python\\python37\\site-packages (from optuna) (1.7.3)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from optuna) (5.1.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from optuna) (1.3.9)\n",
      "Requirement already satisfied: numpy in c:\\users\\yvesd\\appdata\\roaming\\python\\python37\\site-packages (from optuna) (1.21.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (2.4.2)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\yvesd\\appdata\\roaming\\python\\python37\\site-packages (from alembic->optuna) (4.2.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from alembic->optuna) (5.9.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from alembic->optuna) (1.2.1)\n",
      "Requirement already satisfied: autopage>=0.4.0 in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from cliff->optuna) (0.5.1)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from cliff->optuna) (3.3.0)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from cliff->optuna) (2.4.2)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from cliff->optuna) (5.10.0)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from cliff->optuna) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.1)\n",
      "Requirement already satisfied: attrs>=16.3.0 in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (19.2.0)\n",
      "Requirement already satisfied: pyperclip>=1.6 in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.1.7)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from importlib-metadata->alembic->optuna) (3.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\yvesd\\anaconda3\\lib\\site-packages (from Mako->alembic->optuna) (1.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\yvesd\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Intro\n",
    "\n",
    "In this notebook we build a CNN classifier for the problem. The input data for this classifier consists of 1 image of the Gramian Angular Difference field for the past month, 1 image of the area plot of smoothed log prices for the past month, and a collection of numerical data on past month returns & volatility."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Create a custom data loader for the train, test, & validation data\n",
    "class NumericalAndImageDataset(Dataset):\n",
    "    def __init__(self, overview_file: str, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize this dataloader\n",
    "        :param overview_file: location of the overview file\n",
    "        :param transform: transformer for the images\n",
    "        \"\"\"\n",
    "        self.overview= pd.read_csv(overview_file)\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.overview.index)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path_1m = self.overview[\"1_month_img\"].iloc[idx]\n",
    "\n",
    "        img_1m = Image.open(img_path_1m).convert('RGB') # Store image as RGB (3-channel)\n",
    "\n",
    "        label = self.overview.label_1m.iloc[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img_1m = self.transform(img_1m)\n",
    "\n",
    "        return img_1m, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class OneImageNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneImageNet, self).__init__()\n",
    "\n",
    "        self.image_1_features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.image_1_flat = nn.Sequential(\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(15 * 15 * 64, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_1):\n",
    "        step1 = self.image_1_features(img_1)\n",
    "\n",
    "        step1 = step1.view(step1.size(0), -1)\n",
    "\n",
    "        step1 = self.image_1_flat(step1)\n",
    "\n",
    "        return step1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "    running_total = 0\n",
    "\n",
    "    df_collector = []\n",
    "\n",
    "    for img_1ms, labels in test_loader:\n",
    "        outputs = model(img_1ms)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        running_loss += loss.item() * img_1ms.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        act_vs_pred_temp = pd.DataFrame({\n",
    "            \"actual\": labels.data.numpy(),\n",
    "            \"pred\": preds.numpy()\n",
    "        })\n",
    "\n",
    "        df_collector.append(act_vs_pred_temp)\n",
    "\n",
    "        running_total += len(img_1ms)\n",
    "\n",
    "    total_loss = running_loss / running_total\n",
    "    total_acc = running_corrects.double() / running_total\n",
    "\n",
    "    act_vs_pred = pd.concat(df_collector)\n",
    "\n",
    "    return total_loss, total_acc, act_vs_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epochs):\n",
    "    datasets = {'train':train_loader}\n",
    "\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                running_total = 0\n",
    "\n",
    "                for pos, (img_1ms, labels) in enumerate(datasets[phase]):\n",
    "\n",
    "                    outputs = model(img_1ms)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase=='train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    running_loss += loss.item() * img_1ms.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                    running_total += len(img_1ms)\n",
    "\n",
    "                train_losses.append(running_loss / running_total)\n",
    "                train_accs.append(running_corrects / running_total)\n",
    "\n",
    "    return model, train_losses, train_accs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def create_data_loaders(batch_size):\n",
    "    train_data_path = \"ModelData/obs_train.csv\"\n",
    "    test_data_path = \"ModelData/obs_test.csv\"\n",
    "    val_data_path = \"ModelData/obs_val.csv\"\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        # transforms.RandomResizedCrop((224, 224)),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.Resize((30, 30)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        # transforms.Resize((30, 30)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_data = NumericalAndImageDataset(\n",
    "        overview_file=train_data_path,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_data = NumericalAndImageDataset(\n",
    "        overview_file=test_data_path,\n",
    "        transform=test_transform\n",
    "    )\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_data = NumericalAndImageDataset(\n",
    "        overview_file=val_data_path,\n",
    "        transform=test_transform\n",
    "    )\n",
    "    val_data_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_data_loader, test_data_loader, val_data_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-08-19 22:31:49,759]\u001B[0m A new study created in memory with name: no-name-dfc5acbd-bc89-46e5-95fe-89160c789ef8\u001B[0m\n",
      "\u001B[32m[I 2022-08-19 23:33:59,140]\u001B[0m Trial 0 finished with value: 0.6375929682217715 and parameters: {'learning_rate': 0.00018278937444306029, 'epochs': 176, 'batch_size': 1300}. Best is trial 0 with value: 0.6375929682217715.\u001B[0m\n",
      "\u001B[32m[I 2022-08-20 00:03:17,818]\u001B[0m Trial 1 finished with value: 0.398016677935542 and parameters: {'learning_rate': 0.00015557871092569854, 'epochs': 75, 'batch_size': 1541}. Best is trial 0 with value: 0.6375929682217715.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.0001, 0.01),\n",
    "        \"epochs\": trial.suggest_int(\"epochs\", 50, 200),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 64, 2056)\n",
    "    }\n",
    "\n",
    "    train_loader, _, val_loader = create_data_loaders(params[\"batch_size\"])\n",
    "\n",
    "    model = OneImageNet()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"]) # Use adaptive momentum optimizer\n",
    "\n",
    "    model, _, _ = train(model, train_loader, criterion, optimizer, params[\"epochs\"])\n",
    "\n",
    "    _, val_acc, _ = test(model, val_loader, criterion)\n",
    "\n",
    "    return val_acc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for param, value in study.best_trial.params.items():\n",
    "    print(\"{}: {}\".format(param, value))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optuna.visualization.plot_intermediate_values(study)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}