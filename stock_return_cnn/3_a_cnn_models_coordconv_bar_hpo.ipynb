{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://github.com/walsvid/CoordConv/blob/master/coordconv.py\n",
    "https://medium.com/analytics-vidhya/encoding-time-series-as-images-b043becbdbf3\n",
    "https://eng.uber.com/coordconv/\n",
    "https://towardsdatascience.com/reading-charts-with-convolutional-neural-networks-cbaabdd5f478"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prerequisites\n",
    "\n",
    "Run the cells below if the named packages are not installed on your evironment yet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Intro\n",
    "\n",
    "In this notebook we build a CNN classifier for the problem. The input data for this classifier consists of 1 image of the area plot of the prices over the past month of a stock and the target label represents the future 1 month returns of a stock."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Functions\n",
    "First, all the necessary functions to train this model are defined"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Create a custom data loader for the train, test, & validation data\n",
    "class NumericalAndImageDataset(Dataset):\n",
    "    def __init__(self, overview_file: str, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize this dataloader\n",
    "        :param overview_file: location of the overview file\n",
    "        :param transform: transformer for the images\n",
    "        \"\"\"\n",
    "        self.overview= pd.read_csv(overview_file)\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.overview.index)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path_1m_bar = self.overview[\"1_month_img_bar\"].iloc[idx]\n",
    "\n",
    "        img_1m_bar = Image.open(img_path_1m_bar).convert('L') # Store image as greyscale (1-channel)\n",
    "\n",
    "        label = self.overview.label_1m.iloc[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img_1m_bar = self.transform(img_1m_bar)\n",
    "\n",
    "        return img_1m_bar, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class OneImageNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneImageNet, self).__init__()\n",
    "\n",
    "        self.image_1_features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.image_1_flat = nn.Sequential(\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(15 * 15 * 64, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_1):\n",
    "        step1 = self.image_1_features(img_1)\n",
    "\n",
    "        step1 = step1.view(step1.size(0), -1)\n",
    "\n",
    "        step1 = self.image_1_flat(step1)\n",
    "\n",
    "        return step1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion):\n",
    "    \"\"\"\n",
    "    Test the given model\n",
    "\n",
    "    :param model: the model to test\n",
    "    :param test_loader: the dataloader with test data\n",
    "    :param criterion: the loss criterion used for the test\n",
    "    :return: loss, accuracy, and actual vs predicted values\n",
    "    \"\"\"\n",
    "    model.eval() # set model to eval mode\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "    running_total = 0\n",
    "\n",
    "    df_collector = []\n",
    "\n",
    "    for img_1m_bars, labels in test_loader:\n",
    "        outputs = model(img_1m_bars)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        running_loss += loss.item() * img_1m_bars.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        act_vs_pred_temp = pd.DataFrame({\n",
    "            \"actual\": labels.data.numpy(),\n",
    "            \"pred\": preds.numpy()\n",
    "        })\n",
    "\n",
    "        df_collector.append(act_vs_pred_temp)\n",
    "\n",
    "        running_total += len(img_1m_bars)\n",
    "\n",
    "    total_loss = running_loss / running_total\n",
    "    total_acc = running_corrects.double() / running_total\n",
    "\n",
    "    act_vs_pred = pd.concat(df_collector)\n",
    "\n",
    "    return total_loss, total_acc, act_vs_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    \"\"\"\n",
    "    Train the machine learning model\n",
    "\n",
    "    :param model: the model to train\n",
    "    :param train_loader: the data loader with the training data\n",
    "    :param val_loader: the data loader with the validation data\n",
    "    :param criterion: the loss criterion used to train the model\n",
    "    :param optimizer: the optimizer used to train the model\n",
    "    :param epochs: the number of epochs to train the model\n",
    "    :return: the model, training accuracies, training losses, validation accuracies, and validation losses\n",
    "    \"\"\"\n",
    "    datasets = {'train':train_loader}\n",
    "\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                running_total = 0\n",
    "\n",
    "                for pos, (img_1m_bars, labels) in enumerate(datasets[phase]):\n",
    "\n",
    "                    outputs = model(img_1m_bars)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    running_loss += loss.item() * img_1m_bars.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                    running_total += len(img_1m_bars)\n",
    "\n",
    "                train_losses.append(running_loss / running_total)\n",
    "                train_accs.append(running_corrects / running_total)\n",
    "\n",
    "            if phase == \"valid\":\n",
    "                val_loss, val_acc, _ = test(model, val_loader, criterion)\n",
    "                val_losses.append(val_loss)\n",
    "                val_accs.append(val_acc)\n",
    "\n",
    "\n",
    "    return model, train_losses, train_accs, val_losses, val_accs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def create_data_loaders(batch_size):\n",
    "    \"\"\"\n",
    "    Create the train, validation, and test data loaders\n",
    "\n",
    "    :param batch_size: the batch size for the data loaders\n",
    "    :return: the training, validation, and test data loaders\n",
    "    \"\"\"\n",
    "    train_data_path = \"ModelData/obs_train.csv\"\n",
    "    test_data_path = \"ModelData/obs_test.csv\"\n",
    "    val_data_path = \"ModelData/obs_val.csv\"\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        # transforms.RandomResizedCrop((224, 224)),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.Resize((30, 30)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        # transforms.Resize((30, 30)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_data = NumericalAndImageDataset(\n",
    "        overview_file=train_data_path,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_data = NumericalAndImageDataset(\n",
    "        overview_file=test_data_path,\n",
    "        transform=test_transform\n",
    "    )\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_data = NumericalAndImageDataset(\n",
    "        overview_file=val_data_path,\n",
    "        transform=test_transform\n",
    "    )\n",
    "    val_data_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_data_loader, test_data_loader, val_data_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def build_model(params):\n",
    "    \"\"\"\n",
    "    Train the machine learning model and return statistics on test & validation phases\n",
    "    :param params: the hyperparameters for the model\n",
    "    :return: the trained model, training statistics, validation statistics, and test statistics\n",
    "    \"\"\"\n",
    "\n",
    "    train_loader, test_loader, val_loader = create_data_loaders(params[\"batch_size\"])\n",
    "\n",
    "    model = OneImageNet()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"]) # Use adaptive momentum optimizer\n",
    "\n",
    "    model, train_losses, train_accs, val_losses, val_accs = train(model, train_loader, val_loader, criterion, optimizer, params[\"epochs\"])\n",
    "\n",
    "    test_loss, test_acc, act_vs_pred = test(model, test_loader, criterion)\n",
    "\n",
    "    train_performance = {\n",
    "        \"losses\": train_losses,\n",
    "        \"accs\": train_accs\n",
    "    }\n",
    "\n",
    "    validation_performance = {\n",
    "        \"losses\": val_losses,\n",
    "        \"accs\": val_accs\n",
    "    }\n",
    "\n",
    "    test_performance = {\n",
    "        \"loss\": test_loss,\n",
    "        \"acc\": test_acc,\n",
    "        \"act_vs_pred\": act_vs_pred\n",
    "    }\n",
    "\n",
    "    return model, train_performance, validation_performance, test_performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Construct Model\n",
    "Next, the model is trained using a specific selection of hyperparameters (obtained from the hyperparameter tuning from the previous steps) and then finally evaluated on the test set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-618dc0e9d2cd>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m }\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_performance\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_performance\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_performance\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbuild_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-7-b0d498968f16>\u001B[0m in \u001B[0;36mbuild_model\u001B[1;34m(params)\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[0moptimizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moptim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mAdam\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"learning_rate\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# Use adaptive momentum optimizer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m     \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_losses\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_accs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_losses\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_accs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"epochs\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[0mtest_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_acc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mact_vs_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-5-9076fc965892>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(model, train_loader, val_loader, criterion, optimizer, epochs)\u001B[0m\n\u001B[0;32m     35\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[0mphase\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"train\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m                         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 37\u001B[1;33m                         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     38\u001B[0m                         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    305\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    306\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 307\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    308\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    309\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    154\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[0;32m    155\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 156\u001B[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001B[0m\u001B[0;32m    157\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"learning_rate\": 0.0011935110045629637,\n",
    "    \"epochs\": 184,\n",
    "    \"batch_size\": 1864\n",
    "}\n",
    "\n",
    "model, train_performance, validation_performance, test_performance = build_model(params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}